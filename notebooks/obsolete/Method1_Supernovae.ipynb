{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic data for supernovae compilations\n",
    "\n",
    "#### In this notebook, we train an ANN with supernovae compitation.  In order to deal with the covariance matrix, we test two differents ways:\n",
    "\n",
    "1) Add the statistical errors at the covariance matrix $\\Sigma$ of the systematic errors of JLA and Pantheon supernovaes compilation. Then, we use the fact that $\\Sigma$ is symmetrical and we can to use the spectral theorem: $\\Sigma = P D P^T$\n",
    "\n",
    "  and we add $D$ to the dataset to train a neural network as a feature instead the statistical error. \n",
    "  When we make predictions, we need to take a subspace of the original eigenvector matrix P and obtain a new covariance matrix.\n",
    "  \n",
    " 2) We don't use any properties of the matrix, only train ANN with z, $D_L$ and the statistical error. When we make predictions, we take any submatrix of the original covariance matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy as sp\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input,Conv2D,MaxPooling2D,UpSampling2D, Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the JLA covariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "syscov = np.loadtxt('data/pantheon_errors.txt',skiprows=1).reshape((1048,1048))\n",
    "# syscov = np.loadtxt('data/jla_v0_covmatrix.dat',skiprows=1).reshape((740,740))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This matrix have sigly difference in the out diagonal elements, we fix it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "for i in range(len(syscov)):\n",
    "    for j in range(len(syscov)):\n",
    "        if np.iscomplex(syscov[i,j]):\n",
    "            print(\"COMPLEX\")\n",
    "        if syscov[i,j] != syscov[j,i]:\n",
    "#             print(i,j)\n",
    "#             print(syscov[i,j], syscov[j,i]) \n",
    "            count+=1\n",
    "            syscov[j,i] = syscov[i, j]\n",
    "\n",
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, load the data (redshift, $D_L$ and statistical errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'data/pantheon.txt'\n",
    "# file = 'data/jla_lcparams.txt'\n",
    "data = pd.read_csv(file, sep = \" \" ,usecols=['zcmb', 'mb', 'dmb'] )\n",
    "staterr = data.values[:,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For method 1: Adding statistical error to the covariance matrix and vizualize it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1048, 1048) (1048, 1048)\n"
     ]
    }
   ],
   "source": [
    "covfull = np.copy(syscov)\n",
    "covfull[np.diag_indices_from(covfull)] += staterr**2\n",
    "print(np.shape(syscov), np.shape(covfull))\n",
    "mincov = np.min(covfull)\n",
    "maxcov = np.max(covfull)\n",
    "meancov = np.mean(covfull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fbf61e5a7b8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(covfull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fbf617a3710>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_covfull = pd.DataFrame(covfull)\n",
    "sns.heatmap(df_covfull, annot=False, fmt='g', xticklabels=False, yticklabels=False, \n",
    "            cmap = 'inferno', robust=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate eigenvalues and eigenvectors of the new covariance matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1048,) (1048, 1048)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fbf61d29c18>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "eigenval, eigenvec = sp.linalg.eigh(covfull)\n",
    "print(np.shape(eigenval), np.shape(eigenvec))\n",
    "rec_cov = np.matmul(eigenvec, np.diag(eigenval))\n",
    "rec_cov = np.matmul(rec_cov, np.transpose(eigenvec))\n",
    "sns.heatmap(pd.DataFrame(rec_cov), annot=False, fmt='g', xticklabels=False, yticklabels=False, \n",
    "            cmap = 'inferno', robust=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify that there are not complex values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "for i in range(len(eigenvec)):\n",
    "    for j in range(len(eigenvec)):\n",
    "        if np.iscomplex(eigenvec[i,j]):\n",
    "            count+=1\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generation of the data to feed the neural network.\n",
    "\n",
    "#### We need z, $D_L$ and the eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1048, 1) (1048, 3)\n"
     ]
    }
   ],
   "source": [
    "X = data[['zcmb']].values\n",
    "# scalerx = MinMaxScaler(feature_range=(-1,1))\n",
    "# scalerx.fit(X.reshape(-1,1))\n",
    "# X = scalerx.transform(X.reshape(-1,1))\n",
    "# print(data[['mb']].values)\n",
    "\n",
    "dl = np.reshape(data[['mb']].values, (len(X), 1))\n",
    "# scalerdl = MinMaxScaler(feature_range=(-1,1))\n",
    "# scalerdl.fit(dl.reshape(-1,1))\n",
    "# dl = scalerdl.transform(dl.reshape(-1,1))\n",
    "\n",
    "\n",
    "\n",
    "err = np.reshape(data[['dmb']].values, (len(X), 1))\n",
    "eigenval= np.reshape(eigenval, (len(X), 1))\n",
    "\n",
    "# scalereig = MinMaxScaler(feature_range=(-1,1))\n",
    "# scalereig.fit(eigenval.reshape(-1,1))\n",
    "# eigenval = scalereig.transform(eigenval.reshape(-1,1))\n",
    "\n",
    "Y = np.concatenate((dl, eigenval), axis=1)\n",
    "\n",
    "Y = np.concatenate((Y, err), axis=1)\n",
    "print(np.shape(X), np.shape(Y))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle data and split in test and trainning set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.26])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffle = [x for x in range(len(X)) if x%2 ==1]\n",
    "comp = [x for x in range(len(X)) if x%2 ==0]\n",
    "shuffle.extend(comp)\n",
    "split = 0.8\n",
    "\n",
    "X = X[shuffle]\n",
    "Y = Y[shuffle]\n",
    "\n",
    "ntrain = int(split * len(X))\n",
    "indx = [ntrain]\n",
    "X_train, X_test = np.split(X, indx)\n",
    "Y_train, Y_test = np.split(Y, indx)\n",
    "max(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a model and some hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1)]               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               600       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 300)               30300     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 903       \n",
      "=================================================================\n",
      "Total params: 61,903\n",
      "Trainable params: 61,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min',\n",
    "                                   min_delta=0.0001,\n",
    "                                   patience=100,\n",
    "                                   restore_best_weights=True)]\n",
    "#                      tf.keras.callbacks.ReduceLROnPlateau(patience=2)]\n",
    "# initializer = Constant(value=0.01)\n",
    "initializer = tf.keras.initializers.RandomNormal() \n",
    "\n",
    "def model(input_x):\n",
    "    efirst = Dense(300, activation='relu', input_shape=(1,))(input_x)\n",
    "    ehidden = Dense(100, activation='relu')(efirst)\n",
    "    ehidden2 = Dense(300, activation='relu')(ehidden)\n",
    "    elast = Dense(3, activation='linear')(ehidden2)\n",
    "    return elast\n",
    "\n",
    "batch_size = 8\n",
    "epochs = 500\n",
    "input_z = Input(shape = (1,))\n",
    "neural_model = Model(input_z, model(input_z))\n",
    "neural_model.compile(loss='mean_squared_error', optimizer = \"adam\")\n",
    "neural_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 46.8380 - val_loss: 5.5643\n",
      "Epoch 2/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 1.8803 - val_loss: 2.3650\n",
      "Epoch 3/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.6612 - val_loss: 1.1588\n",
      "Epoch 4/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.4986 - val_loss: 0.9926\n",
      "Epoch 5/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.4739 - val_loss: 1.0130\n",
      "Epoch 6/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.4527 - val_loss: 1.0691\n",
      "Epoch 7/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.4077 - val_loss: 0.8047\n",
      "Epoch 8/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.3915 - val_loss: 0.7318\n",
      "Epoch 9/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.3219 - val_loss: 0.6091\n",
      "Epoch 10/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2988 - val_loss: 0.5321\n",
      "Epoch 11/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2559 - val_loss: 0.4544\n",
      "Epoch 12/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2325 - val_loss: 0.4153\n",
      "Epoch 13/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.2033 - val_loss: 0.4031\n",
      "Epoch 14/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.1723 - val_loss: 0.4300\n",
      "Epoch 15/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.1592 - val_loss: 0.2572\n",
      "Epoch 16/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.1612 - val_loss: 0.2650\n",
      "Epoch 17/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.1265 - val_loss: 0.2615\n",
      "Epoch 18/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.1150 - val_loss: 0.2339\n",
      "Epoch 19/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.1157 - val_loss: 0.1876\n",
      "Epoch 20/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.1033 - val_loss: 0.1645\n",
      "Epoch 21/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.1067 - val_loss: 0.1711\n",
      "Epoch 22/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0898 - val_loss: 0.1570\n",
      "Epoch 23/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0943 - val_loss: 0.1471\n",
      "Epoch 24/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0685 - val_loss: 0.1237\n",
      "Epoch 25/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0680 - val_loss: 0.1143\n",
      "Epoch 26/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0648 - val_loss: 0.1174\n",
      "Epoch 27/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0596 - val_loss: 0.1256\n",
      "Epoch 28/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0668 - val_loss: 0.0879\n",
      "Epoch 29/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0587 - val_loss: 0.0856\n",
      "Epoch 30/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0579 - val_loss: 0.0861\n",
      "Epoch 31/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0582 - val_loss: 0.1048\n",
      "Epoch 32/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0569 - val_loss: 0.1213\n",
      "Epoch 33/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0569 - val_loss: 0.0762\n",
      "Epoch 34/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0452 - val_loss: 0.0857\n",
      "Epoch 35/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0427 - val_loss: 0.0718\n",
      "Epoch 36/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0549 - val_loss: 0.0724\n",
      "Epoch 37/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0495 - val_loss: 0.0767\n",
      "Epoch 38/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0620 - val_loss: 0.0914\n",
      "Epoch 39/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0509 - val_loss: 0.0619\n",
      "Epoch 40/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0549 - val_loss: 0.0729\n",
      "Epoch 41/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0511 - val_loss: 0.0664\n",
      "Epoch 42/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0461 - val_loss: 0.1121\n",
      "Epoch 43/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0454 - val_loss: 0.0741\n",
      "Epoch 44/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0392 - val_loss: 0.1038\n",
      "Epoch 45/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0533 - val_loss: 0.0594\n",
      "Epoch 46/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0476 - val_loss: 0.0584\n",
      "Epoch 47/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0442 - val_loss: 0.0821\n",
      "Epoch 48/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0445 - val_loss: 0.0584\n",
      "Epoch 49/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0342 - val_loss: 0.0552\n",
      "Epoch 50/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0364 - val_loss: 0.0580\n",
      "Epoch 51/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0514 - val_loss: 0.1211\n",
      "Epoch 52/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0462 - val_loss: 0.0538\n",
      "Epoch 53/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0342 - val_loss: 0.0584\n",
      "Epoch 54/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0456 - val_loss: 0.1227\n",
      "Epoch 55/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0512 - val_loss: 0.0526\n",
      "Epoch 56/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0395 - val_loss: 0.1055\n",
      "Epoch 57/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0471 - val_loss: 0.0875\n",
      "Epoch 58/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0417 - val_loss: 0.0532\n",
      "Epoch 59/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0454 - val_loss: 0.0636\n",
      "Epoch 60/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0462 - val_loss: 0.0606\n",
      "Epoch 61/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0372 - val_loss: 0.0696\n",
      "Epoch 62/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0394 - val_loss: 0.0492\n",
      "Epoch 63/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0345 - val_loss: 0.1405\n",
      "Epoch 64/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0503 - val_loss: 0.0535\n",
      "Epoch 65/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0359 - val_loss: 0.0453\n",
      "Epoch 66/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0476 - val_loss: 0.0527\n",
      "Epoch 67/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0486 - val_loss: 0.0823\n",
      "Epoch 68/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0434 - val_loss: 0.0540\n",
      "Epoch 69/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0309 - val_loss: 0.0548\n",
      "Epoch 70/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0392 - val_loss: 0.0510\n",
      "Epoch 71/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0408 - val_loss: 0.0595\n",
      "Epoch 72/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0468 - val_loss: 0.0533\n",
      "Epoch 73/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0370 - val_loss: 0.0455\n",
      "Epoch 74/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0433 - val_loss: 0.0764\n",
      "Epoch 75/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0511 - val_loss: 0.0586\n",
      "Epoch 76/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0339 - val_loss: 0.0799\n",
      "Epoch 77/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0372 - val_loss: 0.0786\n",
      "Epoch 78/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0378 - val_loss: 0.0566\n",
      "Epoch 79/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0417 - val_loss: 0.0612\n",
      "Epoch 80/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0309 - val_loss: 0.0589\n",
      "Epoch 81/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0350 - val_loss: 0.0566\n",
      "Epoch 82/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0358 - val_loss: 0.0444\n",
      "Epoch 83/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0413 - val_loss: 0.0992\n",
      "Epoch 84/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0361 - val_loss: 0.0818\n",
      "Epoch 85/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0521 - val_loss: 0.0452\n",
      "Epoch 86/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0286 - val_loss: 0.0506\n",
      "Epoch 87/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0314 - val_loss: 0.0512\n",
      "Epoch 88/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0327 - val_loss: 0.0578\n",
      "Epoch 89/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0337 - val_loss: 0.0398\n",
      "Epoch 90/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0461 - val_loss: 0.0411\n",
      "Epoch 91/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0496 - val_loss: 0.0539\n",
      "Epoch 92/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0376 - val_loss: 0.1110\n",
      "Epoch 93/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0313 - val_loss: 0.0468\n",
      "Epoch 94/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0421 - val_loss: 0.0740\n",
      "Epoch 95/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0390 - val_loss: 0.0433\n",
      "Epoch 96/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0311 - val_loss: 0.0387\n",
      "Epoch 97/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0316 - val_loss: 0.0400\n",
      "Epoch 98/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0379 - val_loss: 0.0496\n",
      "Epoch 99/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0436 - val_loss: 0.1615\n",
      "Epoch 100/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0310 - val_loss: 0.0382\n",
      "Epoch 101/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0339 - val_loss: 0.0432\n",
      "Epoch 102/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0307 - val_loss: 0.0354\n",
      "Epoch 103/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0268 - val_loss: 0.0383\n",
      "Epoch 104/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0288 - val_loss: 0.0361\n",
      "Epoch 105/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0272 - val_loss: 0.0394\n",
      "Epoch 106/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0261 - val_loss: 0.0563\n",
      "Epoch 107/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0327 - val_loss: 0.0360\n",
      "Epoch 108/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0236 - val_loss: 0.0357\n",
      "Epoch 109/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0271 - val_loss: 0.0364\n",
      "Epoch 110/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0340 - val_loss: 0.0322\n",
      "Epoch 111/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0384 - val_loss: 0.0403\n",
      "Epoch 112/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0371 - val_loss: 0.0299\n",
      "Epoch 113/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0264 - val_loss: 0.0426\n",
      "Epoch 114/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0338 - val_loss: 0.0309\n",
      "Epoch 115/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0261 - val_loss: 0.0487\n",
      "Epoch 116/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0292 - val_loss: 0.0316\n",
      "Epoch 117/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0248 - val_loss: 0.0380\n",
      "Epoch 118/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0294 - val_loss: 0.1148\n",
      "Epoch 119/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0392 - val_loss: 0.0583\n",
      "Epoch 120/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0349 - val_loss: 0.0418\n",
      "Epoch 121/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0301 - val_loss: 0.0431\n",
      "Epoch 122/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0328 - val_loss: 0.0359\n",
      "Epoch 123/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0272 - val_loss: 0.0359\n",
      "Epoch 124/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0240 - val_loss: 0.0442\n",
      "Epoch 125/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0290 - val_loss: 0.0271\n",
      "Epoch 126/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0319 - val_loss: 0.0332\n",
      "Epoch 127/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0311 - val_loss: 0.0367\n",
      "Epoch 128/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0269 - val_loss: 0.0272\n",
      "Epoch 129/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0257 - val_loss: 0.0347\n",
      "Epoch 130/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0248 - val_loss: 0.0808\n",
      "Epoch 131/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0314 - val_loss: 0.0844\n",
      "Epoch 132/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0484 - val_loss: 0.0301\n",
      "Epoch 133/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0216 - val_loss: 0.0272\n",
      "Epoch 134/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0237 - val_loss: 0.0373\n",
      "Epoch 135/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0262 - val_loss: 0.0306\n",
      "Epoch 136/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0230 - val_loss: 0.0344\n",
      "Epoch 137/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0312 - val_loss: 0.0423\n",
      "Epoch 138/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0280 - val_loss: 0.0282\n",
      "Epoch 139/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0286 - val_loss: 0.0391\n",
      "Epoch 140/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0222 - val_loss: 0.0414\n",
      "Epoch 141/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0267 - val_loss: 0.0943\n",
      "Epoch 142/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0353 - val_loss: 0.0295\n",
      "Epoch 143/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0304 - val_loss: 0.0363\n",
      "Epoch 144/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0322 - val_loss: 0.0266\n",
      "Epoch 145/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0233 - val_loss: 0.0305\n",
      "Epoch 146/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0210 - val_loss: 0.0287\n",
      "Epoch 147/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0306 - val_loss: 0.0272\n",
      "Epoch 148/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0335 - val_loss: 0.0403\n",
      "Epoch 149/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0422 - val_loss: 0.1405\n",
      "Epoch 150/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0398 - val_loss: 0.0320\n",
      "Epoch 151/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0237 - val_loss: 0.0299\n",
      "Epoch 152/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0364 - val_loss: 0.0296\n",
      "Epoch 153/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0271 - val_loss: 0.0341\n",
      "Epoch 154/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0245 - val_loss: 0.0332\n",
      "Epoch 155/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0261 - val_loss: 0.0433\n",
      "Epoch 156/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0240 - val_loss: 0.0501\n",
      "Epoch 157/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0490 - val_loss: 0.1140\n",
      "Epoch 158/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0263 - val_loss: 0.0299\n",
      "Epoch 159/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0238 - val_loss: 0.0278\n",
      "Epoch 160/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0213 - val_loss: 0.0275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0343 - val_loss: 0.0453\n",
      "Epoch 162/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0226 - val_loss: 0.0316\n",
      "Epoch 163/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0224 - val_loss: 0.0252\n",
      "Epoch 164/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0218 - val_loss: 0.0410\n",
      "Epoch 165/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0545 - val_loss: 0.0667\n",
      "Epoch 166/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0276 - val_loss: 0.0401\n",
      "Epoch 167/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0240 - val_loss: 0.0420\n",
      "Epoch 168/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0267 - val_loss: 0.0530\n",
      "Epoch 169/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0261 - val_loss: 0.0690\n",
      "Epoch 170/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0308 - val_loss: 0.0877\n",
      "Epoch 171/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0292 - val_loss: 0.0380\n",
      "Epoch 172/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0233 - val_loss: 0.0311\n",
      "Epoch 173/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0314 - val_loss: 0.0263\n",
      "Epoch 174/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0247 - val_loss: 0.0419\n",
      "Epoch 175/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0226 - val_loss: 0.0281\n",
      "Epoch 176/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0246 - val_loss: 0.0287\n",
      "Epoch 177/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0332 - val_loss: 0.0295\n",
      "Epoch 178/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0284 - val_loss: 0.0458\n",
      "Epoch 179/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0296 - val_loss: 0.0409\n",
      "Epoch 180/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0253 - val_loss: 0.0239\n",
      "Epoch 181/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0281 - val_loss: 0.1242\n",
      "Epoch 182/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0282 - val_loss: 0.0241\n",
      "Epoch 183/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0230 - val_loss: 0.0286\n",
      "Epoch 184/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0239 - val_loss: 0.0244\n",
      "Epoch 185/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0244 - val_loss: 0.0361\n",
      "Epoch 186/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0278 - val_loss: 0.0581\n",
      "Epoch 187/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0269 - val_loss: 0.0620\n",
      "Epoch 188/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0250 - val_loss: 0.0216\n",
      "Epoch 189/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0221 - val_loss: 0.0531\n",
      "Epoch 190/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0406 - val_loss: 0.0378\n",
      "Epoch 191/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0234 - val_loss: 0.0394\n",
      "Epoch 192/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0364 - val_loss: 0.0300\n",
      "Epoch 193/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0219 - val_loss: 0.0247\n",
      "Epoch 194/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0333 - val_loss: 0.0373\n",
      "Epoch 195/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0235 - val_loss: 0.0220\n",
      "Epoch 196/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0253 - val_loss: 0.0311\n",
      "Epoch 197/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0213 - val_loss: 0.0228\n",
      "Epoch 198/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0209 - val_loss: 0.0379\n",
      "Epoch 199/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0228 - val_loss: 0.0278\n",
      "Epoch 200/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0235 - val_loss: 0.0246\n",
      "Epoch 201/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0270 - val_loss: 0.0291\n",
      "Epoch 202/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0210 - val_loss: 0.0239\n",
      "Epoch 203/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0326 - val_loss: 0.0313\n",
      "Epoch 204/500\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0377 - val_loss: 0.0492\n",
      "Epoch 205/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0235 - val_loss: 0.0300\n",
      "Epoch 206/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0224 - val_loss: 0.0348\n",
      "Epoch 207/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0254 - val_loss: 0.0259\n",
      "Epoch 208/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0294 - val_loss: 0.0252\n",
      "Epoch 209/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0330 - val_loss: 0.0396\n",
      "Epoch 210/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0284 - val_loss: 0.0585\n",
      "Epoch 211/500\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0324 - val_loss: 0.0228\n",
      "Epoch 212/500\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0208 - val_loss: 0.0283\n",
      "Epoch 213/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0313 - val_loss: 0.0308\n",
      "Epoch 214/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0188 - val_loss: 0.0330\n",
      "Epoch 215/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0211 - val_loss: 0.0265\n",
      "Epoch 216/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0325 - val_loss: 0.0271\n",
      "Epoch 217/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0277 - val_loss: 0.0432\n",
      "Epoch 218/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0333 - val_loss: 0.0244\n",
      "Epoch 219/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0340 - val_loss: 0.0214\n",
      "Epoch 220/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0194 - val_loss: 0.0241\n",
      "Epoch 221/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0250 - val_loss: 0.0283\n",
      "Epoch 222/500\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0219 - val_loss: 0.0262\n",
      "Epoch 223/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0570 - val_loss: 0.0367\n",
      "Epoch 224/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0281 - val_loss: 0.0255\n",
      "Epoch 225/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0203 - val_loss: 0.0654\n",
      "Epoch 226/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0272 - val_loss: 0.0234\n",
      "Epoch 227/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0196 - val_loss: 0.0267\n",
      "Epoch 228/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0236 - val_loss: 0.0218\n",
      "Epoch 229/500\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0255 - val_loss: 0.0322\n",
      "Epoch 230/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0235 - val_loss: 0.0215\n",
      "Epoch 231/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0299 - val_loss: 0.0250\n",
      "Epoch 232/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0230 - val_loss: 0.0202\n",
      "Epoch 233/500\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0314 - val_loss: 0.0226\n",
      "Epoch 234/500\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0212 - val_loss: 0.0349\n",
      "Epoch 235/500\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0470 - val_loss: 0.0370\n",
      "Epoch 236/500\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0217 - val_loss: 0.0275\n",
      "Epoch 237/500\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.0219 - val_loss: 0.0329\n",
      "Epoch 238/500\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.0223 - val_loss: 0.0271\n",
      "Epoch 239/500\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0304 - val_loss: 0.0215\n",
      "Epoch 240/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0203 - val_loss: 0.0373\n",
      "Epoch 241/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0234 - val_loss: 0.0330\n",
      "Epoch 242/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0224 - val_loss: 0.0578\n",
      "Epoch 243/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0527 - val_loss: 0.0589\n",
      "Epoch 244/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0243 - val_loss: 0.0258\n",
      "Epoch 245/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0194 - val_loss: 0.0318\n",
      "Epoch 246/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0309 - val_loss: 0.0257\n",
      "Epoch 247/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0398\n",
      "Epoch 248/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0314 - val_loss: 0.0817\n",
      "Epoch 249/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0224 - val_loss: 0.0232\n",
      "Epoch 250/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0202 - val_loss: 0.0252\n",
      "Epoch 251/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0206 - val_loss: 0.0235\n",
      "Epoch 252/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0242 - val_loss: 0.0431\n",
      "Epoch 253/500\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0259 - val_loss: 0.0208\n",
      "Epoch 254/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0278 - val_loss: 0.0237\n",
      "Epoch 255/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0260 - val_loss: 0.1086\n",
      "Epoch 256/500\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0283 - val_loss: 0.0218\n",
      "Epoch 257/500\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0338 - val_loss: 0.0353\n",
      "Epoch 258/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0207 - val_loss: 0.0376\n",
      "Epoch 259/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0245 - val_loss: 0.0932\n",
      "Epoch 260/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0222 - val_loss: 0.0240\n",
      "Epoch 261/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.0256\n",
      "Epoch 262/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0264 - val_loss: 0.0316\n",
      "Epoch 263/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0261 - val_loss: 0.0262\n",
      "Epoch 264/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0310 - val_loss: 0.0223\n",
      "Epoch 265/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0227 - val_loss: 0.0663\n",
      "Epoch 266/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0257 - val_loss: 0.0312\n",
      "Epoch 267/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0217 - val_loss: 0.0277\n",
      "Epoch 268/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0364 - val_loss: 0.0523\n",
      "Epoch 269/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0354 - val_loss: 0.0306\n",
      "Epoch 270/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0256 - val_loss: 0.0249\n",
      "Epoch 271/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0302 - val_loss: 0.0240\n",
      "Epoch 272/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0241 - val_loss: 0.0318\n",
      "Epoch 273/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0270 - val_loss: 0.0207\n",
      "Epoch 274/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0212 - val_loss: 0.0256\n",
      "Epoch 275/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0223 - val_loss: 0.0299\n",
      "Epoch 276/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0258 - val_loss: 0.0312\n",
      "Epoch 277/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0295 - val_loss: 0.0250\n",
      "Epoch 278/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0250 - val_loss: 0.0216\n",
      "Epoch 279/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0237 - val_loss: 0.0417\n",
      "Epoch 280/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0224 - val_loss: 0.0207\n",
      "Epoch 281/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0338 - val_loss: 0.0399\n",
      "Epoch 282/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0250 - val_loss: 0.0378\n",
      "Epoch 283/500\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0284 - val_loss: 0.0529\n",
      "Epoch 284/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0280 - val_loss: 0.0391\n",
      "Epoch 285/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0293\n",
      "Epoch 286/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0229 - val_loss: 0.0480\n",
      "Epoch 287/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0700 - val_loss: 0.0221\n",
      "Epoch 288/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0262 - val_loss: 0.0282\n",
      "Epoch 289/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0192 - val_loss: 0.0221\n",
      "Epoch 290/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0296 - val_loss: 0.0246\n",
      "Epoch 291/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0203 - val_loss: 0.0227\n",
      "Epoch 292/500\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0224 - val_loss: 0.0236\n",
      "Epoch 293/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0235 - val_loss: 0.0205\n",
      "Epoch 294/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0167 - val_loss: 0.0205\n",
      "Epoch 295/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0270 - val_loss: 0.0310\n",
      "Epoch 296/500\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0200 - val_loss: 0.0262\n",
      "Epoch 297/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0254 - val_loss: 0.0232\n",
      "Epoch 298/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0197 - val_loss: 0.0537\n",
      "Epoch 299/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0224 - val_loss: 0.0259\n",
      "Epoch 300/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0206 - val_loss: 0.0207\n",
      "Epoch 301/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0254 - val_loss: 0.0292\n",
      "Epoch 302/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0399 - val_loss: 0.0316\n",
      "Epoch 303/500\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0215 - val_loss: 0.0219\n",
      "Epoch 304/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0273 - val_loss: 0.0271\n",
      "Epoch 305/500\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0258 - val_loss: 0.0233\n",
      "Epoch 306/500\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0215 - val_loss: 0.0305\n",
      "Epoch 307/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0214 - val_loss: 0.0232\n",
      "Epoch 308/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0210 - val_loss: 0.0270\n",
      "Epoch 309/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0252 - val_loss: 0.0191\n",
      "Epoch 310/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0247\n",
      "Epoch 311/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0188 - val_loss: 0.0235\n",
      "Epoch 312/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0234 - val_loss: 0.0258\n",
      "Epoch 313/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0318 - val_loss: 0.0264\n",
      "Epoch 314/500\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0307 - val_loss: 0.0245\n",
      "Epoch 315/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0240 - val_loss: 0.0222\n",
      "Epoch 316/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0412 - val_loss: 0.0264\n",
      "Epoch 317/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0263 - val_loss: 0.0565\n",
      "Epoch 318/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0478 - val_loss: 0.0227\n",
      "Epoch 319/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0179 - val_loss: 0.0240\n",
      "Epoch 320/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0262 - val_loss: 0.0777\n",
      "Epoch 321/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0235 - val_loss: 0.0481\n",
      "Epoch 322/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0199 - val_loss: 0.0225\n",
      "Epoch 323/500\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0211 - val_loss: 0.0233\n",
      "Epoch 324/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0206 - val_loss: 0.0210\n",
      "Epoch 325/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0309 - val_loss: 0.0203\n",
      "Epoch 326/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0234 - val_loss: 0.0321\n",
      "Epoch 327/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0222 - val_loss: 0.0234\n",
      "Epoch 328/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0241 - val_loss: 0.0226\n",
      "Epoch 329/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0204 - val_loss: 0.0210\n",
      "Epoch 330/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0199 - val_loss: 0.0209\n",
      "Epoch 331/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0207 - val_loss: 0.0310\n",
      "Epoch 332/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0231 - val_loss: 0.0333\n",
      "Epoch 333/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0375 - val_loss: 0.0288\n",
      "Epoch 334/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0232 - val_loss: 0.0307\n",
      "Epoch 335/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0257 - val_loss: 0.0479\n",
      "Epoch 336/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0335 - val_loss: 0.0290\n",
      "Epoch 337/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0259 - val_loss: 0.0766\n",
      "Epoch 338/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0250 - val_loss: 0.0214\n",
      "Epoch 339/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0160 - val_loss: 0.0286\n",
      "Epoch 340/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0228 - val_loss: 0.0221\n",
      "Epoch 341/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0327 - val_loss: 0.0403\n",
      "Epoch 342/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0427\n",
      "Epoch 343/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0240 - val_loss: 0.0294\n",
      "Epoch 344/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0243 - val_loss: 0.0220\n",
      "Epoch 345/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0223 - val_loss: 0.0276\n",
      "Epoch 346/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0235 - val_loss: 0.0275\n",
      "Epoch 347/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0227 - val_loss: 0.0228\n",
      "Epoch 348/500\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0217 - val_loss: 0.0272\n",
      "Epoch 349/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0209 - val_loss: 0.0304\n",
      "Epoch 350/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0275 - val_loss: 0.0233\n",
      "Epoch 351/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0457 - val_loss: 0.0224\n",
      "Epoch 352/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0211 - val_loss: 0.0476\n",
      "Epoch 353/500\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0177 - val_loss: 0.0295\n",
      "Epoch 354/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0249 - val_loss: 0.0338\n",
      "Epoch 355/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0243 - val_loss: 0.0343\n",
      "Epoch 356/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0288 - val_loss: 0.0225\n",
      "Epoch 357/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0195 - val_loss: 0.0199\n",
      "Epoch 358/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0496 - val_loss: 0.0745\n",
      "Epoch 359/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0309 - val_loss: 0.0225\n",
      "Epoch 360/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0210 - val_loss: 0.0218\n",
      "Epoch 361/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0221 - val_loss: 0.0286\n",
      "Epoch 362/500\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0282 - val_loss: 0.0216\n",
      "Epoch 363/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0313\n",
      "Epoch 364/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0210 - val_loss: 0.0243\n",
      "Epoch 365/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0281 - val_loss: 0.0280\n",
      "Epoch 366/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0199 - val_loss: 0.0358\n",
      "Epoch 367/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0216 - val_loss: 0.0445\n",
      "Epoch 368/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0265 - val_loss: 0.0202\n",
      "Epoch 369/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0200 - val_loss: 0.0205\n",
      "Epoch 370/500\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0315 - val_loss: 0.0258\n",
      "Epoch 371/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0219 - val_loss: 0.1032\n",
      "Epoch 372/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0255 - val_loss: 0.0240\n",
      "Epoch 373/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0198 - val_loss: 0.0650\n",
      "Epoch 374/500\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0215 - val_loss: 0.0271\n",
      "Epoch 375/500\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0236 - val_loss: 0.0195\n",
      "Epoch 376/500\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0368 - val_loss: 0.0192\n",
      "Epoch 377/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0228 - val_loss: 0.0245\n",
      "Epoch 378/500\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0214 - val_loss: 0.0509\n",
      "Epoch 379/500\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0523 - val_loss: 0.0474\n",
      "Epoch 380/500\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0277 - val_loss: 0.0644\n",
      "Epoch 381/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0213 - val_loss: 0.0317\n",
      "Epoch 382/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0261 - val_loss: 0.0293\n",
      "Epoch 383/500\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0232 - val_loss: 0.0223\n",
      "Epoch 384/500\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0194 - val_loss: 0.0222\n",
      "Epoch 385/500\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0187 - val_loss: 0.0243\n",
      "Epoch 386/500\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0214 - val_loss: 0.0300\n",
      "Epoch 387/500\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.0203 - val_loss: 0.0343\n",
      "Epoch 388/500\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0272 - val_loss: 0.0302\n",
      "Epoch 389/500\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0334 - val_loss: 0.0262\n",
      "Epoch 390/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0287 - val_loss: 0.0248\n",
      "Epoch 391/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0191 - val_loss: 0.0473\n",
      "Epoch 392/500\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0202 - val_loss: 0.0200\n",
      "Epoch 393/500\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.0329 - val_loss: 0.0460\n",
      "Epoch 394/500\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0262 - val_loss: 0.0212\n",
      "Epoch 395/500\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0204 - val_loss: 0.0330\n",
      "Epoch 396/500\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0255 - val_loss: 0.0226\n",
      "Epoch 397/500\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0281 - val_loss: 0.0267\n",
      "Epoch 398/500\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0421 - val_loss: 0.0262\n",
      "Epoch 399/500\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.0209 - val_loss: 0.0342\n",
      "Epoch 400/500\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.0305 - val_loss: 0.0359\n",
      "Epoch 401/500\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0210 - val_loss: 0.0213\n",
      "Epoch 402/500\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.0319 - val_loss: 0.0414\n",
      "Epoch 403/500\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.0181 - val_loss: 0.0230\n",
      "Epoch 404/500\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0215 - val_loss: 0.0227\n",
      "Epoch 405/500\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0226 - val_loss: 0.0221\n",
      "Epoch 406/500\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0224 - val_loss: 0.0226\n",
      "Epoch 407/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0247 - val_loss: 0.0503\n",
      "Epoch 408/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0370 - val_loss: 0.0260\n",
      "Epoch 409/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0231 - val_loss: 0.0235\n"
     ]
    }
   ],
   "source": [
    "model_train = neural_model.fit(X_train, Y_train, batch_size=batch_size,\n",
    "                                    epochs=epochs, verbose=1,\n",
    "                                    validation_data=(X_test, Y_test),\n",
    "                                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model_train.history['loss'], color='r', )\n",
    "plt.plot(model_train.history['val_loss'], color='g')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.title('MSE = {}'.format(np.min(model_train.history['val_loss'])))\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.savefig(\"loss_pantheon.png\", dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ranz = np.random.uniform(0, 2, size=100)\n",
    "ranz = np.linspace(0.01, 2.3, 100)\n",
    "pred_random = neural_model.predict(ranz)\n",
    "# pred_random\n",
    "np.shape(pred_random[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1: Now we can construct a covariance matrix of lower dimension generating the eigenvalues for the new subspace and using a cutted matrix from the eigenvector orthonormalized matrix that this should be a base of the subspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 100)\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "new_D = np.diag(pred_random[:, 1])\n",
    "print(np.shape(new_D))\n",
    "subspaceDim = len(new_D)\n",
    "reduce_eigenvec = eigenvec[:subspaceDim, :subspaceDim]\n",
    "print(subspaceDim)\n",
    "trans_eigenvec = np.transpose(reduce_eigenvec)\n",
    "new_cov = np.matmul(reduce_eigenvec, new_D)\n",
    "new_cov = np.matmul(new_cov, trans_eigenvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(pd.DataFrame(new_cov), annot=False, fmt='g', xticklabels=False, yticklabels=False, \n",
    "            cmap = 'inferno', robust=False, cbar=True)\n",
    "\n",
    "plt.savefig(\"cov_method1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"pantheoncov_method1_nn.txt\", new_cov.reshape(100*100), delimiter= \" \", header=\"#100 100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mookSN = np.concatenate((ranz.reshape(-1,1), pred_random[:,:2]), axis=1)\n",
    "np.savetxt(\"pantheonDATA_method1_nn.txt\", mookSN, delimiter= \" \", header=\"#z dm err\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
